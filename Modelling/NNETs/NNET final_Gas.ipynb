{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ca6139f-8132-4b02-b725-b5908c648fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error,  r2_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import kerastuner as kt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73f8853e-6d6a-4cf3-8cd7-ca8c9a5a7277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            building_name        meter        date  meter_reading site_name  \\\n",
      "0  Bear_education_Alfredo  electricity  2016-01-01         2.9050      Bear   \n",
      "1  Bear_education_Alfredo  electricity  2016-01-02         2.7700      Bear   \n",
      "2  Bear_education_Alfredo  electricity  2016-01-03         2.6725      Bear   \n",
      "3  Bear_education_Alfredo  electricity  2016-01-04         4.5650      Bear   \n",
      "4  Bear_education_Alfredo  electricity  2016-01-05         4.7825      Bear   \n",
      "\n",
      "  sub_primaryspaceusage    sqm    sqft    timezone  airTemperature  \\\n",
      "0             Education  609.8  6564.0  US/Pacific        5.246861   \n",
      "1             Education  609.8  6564.0  US/Pacific        5.993973   \n",
      "2             Education  609.8  6564.0  US/Pacific        5.660314   \n",
      "3             Education  609.8  6564.0  US/Pacific        5.048507   \n",
      "4             Education  609.8  6564.0  US/Pacific        4.745567   \n",
      "\n",
      "   cloudCoverage  dewTemperature  precipDepth1HR  precipDepth6HR  \\\n",
      "0       1.927009        0.254484        0.351088       10.801125   \n",
      "1       1.997893        0.892188        0.409453       11.105558   \n",
      "2       1.946017        0.778475        0.552568       11.167389   \n",
      "3       1.987616       -0.268905        0.479493       11.089874   \n",
      "4       2.007311        0.321921        1.033857       11.723586   \n",
      "\n",
      "   seaLvlPressure  windDirection  windSpeed  season  building_id  site_id  \n",
      "0     1018.888301     172.924863   3.807399  Winter            1        1  \n",
      "1     1014.347411     181.359441   4.202455  Winter            1        1  \n",
      "2     1010.396019     208.978674   4.015919  Winter            1        1  \n",
      "3     1008.903334     211.377040   3.909701  Winter            1        1  \n",
      "4     1012.747700     170.002007   3.528571  Winter            1        1  \n",
      "            building_name        meter        date  meter_reading site_name  \\\n",
      "0  Bear_education_Alfredo  electricity  2017-01-01         2.1775      Bear   \n",
      "1  Bear_education_Alfredo  electricity  2017-01-02         2.7925      Bear   \n",
      "2  Bear_education_Alfredo  electricity  2017-01-03         7.1100      Bear   \n",
      "3  Bear_education_Alfredo  electricity  2017-01-04         6.8450      Bear   \n",
      "4  Bear_education_Alfredo  electricity  2017-01-05         3.9500      Bear   \n",
      "\n",
      "  sub_primaryspaceusage    sqm    sqft    timezone  airTemperature  \\\n",
      "0             Education  609.8  6564.0  US/Pacific        6.313140   \n",
      "1             Education  609.8  6564.0  US/Pacific        5.297363   \n",
      "2             Education  609.8  6564.0  US/Pacific        5.970330   \n",
      "3             Education  609.8  6564.0  US/Pacific        5.959649   \n",
      "4             Education  609.8  6564.0  US/Pacific        1.717660   \n",
      "\n",
      "   cloudCoverage  dewTemperature  precipDepth1HR  precipDepth6HR  \\\n",
      "0       2.126542        1.751662        0.414432       11.077130   \n",
      "1       1.923200        2.274505        0.930626       11.221247   \n",
      "2       2.180302        3.279560        2.242145       12.169223   \n",
      "3       2.309525        1.680482        1.715769       12.168157   \n",
      "4       2.071431       -3.608609        0.294415       10.758541   \n",
      "\n",
      "   seaLvlPressure  windDirection  windSpeed  season  building_id  site_id  \n",
      "0     1017.729660     167.173422   3.224944  Winter            1        1  \n",
      "1     1023.168730     128.275621   3.071918  Winter            1        1  \n",
      "2     1017.886469     178.171787   3.910330  Winter            1        1  \n",
      "3     1013.028823     243.891423   3.783333  Winter            1        1  \n",
      "4     1018.172131     207.449203   2.771794  Winter            1        1  \n"
     ]
    }
   ],
   "source": [
    "# Loading the dataset\n",
    "# Train Data\n",
    "temp_df = pd.read_csv(\"../../data/cleaned/train.csv\", nrows=0)  # Read only the header\n",
    "total_columns = len(temp_df.columns)\n",
    "columns_to_use = temp_df.columns[1:total_columns]\n",
    "train_data = pd.read_csv(\"../../data/cleaned/train.csv\",  usecols=columns_to_use)\n",
    "print(train_data.head(5))\n",
    "# Test Data\n",
    "test_data = pd.read_csv(\"../../data/cleaned/test.csv\", usecols=columns_to_use)\n",
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80666069-c818-4a0c-b571-994016202bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['electricity', 'chilledwater', 'gas', 'hotwater', 'solar', 'water',\n",
       "       'steam', 'irrigation'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['meter'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a35fbac5-5d84-4b88-adf8-fb13549d2bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the columns that are not relevant to our analysis\n",
    "train_data = train_data.drop(columns=['building_name', 'site_name'])\n",
    "test_data = test_data.drop(columns=['building_name', 'site_name'])\n",
    "\n",
    "train_data = train_data[(train_data['meter'] == 'electricity') | (train_data['meter'] == 'chilledwater') | (train_data['meter'] == 'steam')\n",
    "| (train_data['meter'] == 'hotwater') | (train_data['meter'] == 'gas')]\n",
    "\n",
    "test_data = test_data[(test_data['meter'] == 'electricity') | (test_data['meter'] == 'chilledwater') | (test_data['meter'] == 'steam')\n",
    "| (test_data['meter'] == 'hotwater') | (test_data['meter'] == 'gas')]\n",
    "\n",
    "# Building index on building_id for further assessment\n",
    "train_data.set_index('building_id', inplace=True)\n",
    "test_data.set_index('building_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "609ef3da-792c-4ef5-a954-9bd0b3c4f7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering for gas meter_reading\n",
    "train_data = train_data[train_data['meter'] == 'gas']\n",
    "test_data = test_data[test_data['meter'] == 'gas']\n",
    "\n",
    "train_data = train_data.drop(columns=['meter'])\n",
    "test_data = test_data.drop(columns=['meter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0b4676f-eb9c-4e03-a002-115dbfe3349f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   date  meter_reading        sub_primaryspaceusage     sqm  \\\n",
      "building_id                                                                   \n",
      "337          2016-05-02        377.491  Primary/Secondary Classroom  9005.0   \n",
      "354          2016-09-20        211.569  Primary/Secondary Classroom  2335.0   \n",
      "\n",
      "                sqft       timezone  airTemperature  cloudCoverage  \\\n",
      "building_id                                                          \n",
      "337          96929.0  Europe/London       14.796923       2.082518   \n",
      "354          25134.0  Europe/London       20.850439       2.058763   \n",
      "\n",
      "             dewTemperature  precipDepth1HR  precipDepth6HR  seaLvlPressure  \\\n",
      "building_id                                                                   \n",
      "337                9.096044        2.127750       12.484141     1016.285599   \n",
      "354               14.417105        0.605524       11.645330     1017.070180   \n",
      "\n",
      "             windDirection  windSpeed  season  site_id  \n",
      "building_id                                             \n",
      "337             176.058013   3.784396  Spring        9  \n",
      "354             168.347690   2.571711    Fall        9  \n",
      "-------------------------------------------------------------\n",
      "                   date  meter_reading        sub_primaryspaceusage     sqm  \\\n",
      "building_id                                                                   \n",
      "383          2017-03-02       1647.496  Primary/Secondary Classroom  6149.0   \n",
      "372          2017-12-12       2107.888  Primary/Secondary Classroom  2937.0   \n",
      "\n",
      "                sqft       timezone  airTemperature  cloudCoverage  \\\n",
      "building_id                                                          \n",
      "383          66187.0  Europe/London           7.546       1.727301   \n",
      "372          31614.0  Europe/London           4.775       1.929325   \n",
      "\n",
      "             dewTemperature  precipDepth1HR  precipDepth6HR  seaLvlPressure  \\\n",
      "building_id                                                                   \n",
      "383               -1.176222        0.341686       12.134194     1016.347228   \n",
      "372               -1.393627        0.169415       10.862973     1013.941971   \n",
      "\n",
      "             windDirection  windSpeed  season  site_id  \n",
      "building_id                                             \n",
      "383             223.192992   5.670000  Spring        9  \n",
      "372             202.265904   3.548039  Winter        9  \n"
     ]
    }
   ],
   "source": [
    "# Inspecting the data frames\n",
    "print(train_data.sample(2))\n",
    "print('-------------------------------------------------------------')\n",
    "print(test_data.sample(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75abc748-d8bf-4b49-815d-979cba143f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating into X and Y dataframes\n",
    "X_train = train_data.drop(columns=['meter_reading'])  # Exclude target variable\n",
    "y_train = train_data['meter_reading']\n",
    "\n",
    "X_test = test_data.drop(columns=['meter_reading'])  # Exclude target variable\n",
    "y_test = test_data['meter_reading']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6c0c0cd-43ef-427d-97ba-d5c31aacf747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'site_id' from numeric to categorical\n",
    "X_train['site_id'] = X_train['site_id'].astype('category')\n",
    "X_test['site_id'] = X_test['site_id'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1cc3382-f4df-4e09-a935-93306c5e3eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date                       object\n",
      "sub_primaryspaceusage      object\n",
      "sqm                       float64\n",
      "sqft                      float64\n",
      "timezone                   object\n",
      "airTemperature            float64\n",
      "cloudCoverage             float64\n",
      "dewTemperature            float64\n",
      "precipDepth1HR            float64\n",
      "precipDepth6HR            float64\n",
      "seaLvlPressure            float64\n",
      "windDirection             float64\n",
      "windSpeed                 float64\n",
      "season                     object\n",
      "site_id                  category\n",
      "dtype: object\n",
      "Index(['date', 'sub_primaryspaceusage', 'sqm', 'sqft', 'timezone',\n",
      "       'airTemperature', 'cloudCoverage', 'dewTemperature', 'precipDepth1HR',\n",
      "       'precipDepth6HR', 'seaLvlPressure', 'windDirection', 'windSpeed',\n",
      "       'season', 'site_id'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(X_train.dtypes)\n",
    "print(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26481f29-0b4f-42b8-8b02-89086982432f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and types based on your dataset\n",
    "numerical_features = ['sqm', 'sqft', 'airTemperature', 'cloudCoverage', 'dewTemperature',\n",
    "                      'precipDepth1HR', 'precipDepth6HR', 'seaLvlPressure', 'windDirection', 'windSpeed']\n",
    "categorical_features = ['timezone', 'season', 'sub_primaryspaceusage', 'site_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08132472-5878-49eb-be6a-157a7f8a8f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', MinMaxScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d3d2e20-1a12-420d-a7db-4f6e7ab4de8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', MinMaxScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Fit the preprocessor on the training data and transform both training and test data\n",
    "preprocessor.fit(X_train)\n",
    "X_train_processed = preprocessor.transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eae425e1-383d-4d28-956b-ee768b111a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the processed data back to dense DataFrames\n",
    "X_train_processed_df = pd.DataFrame(X_train_processed, columns=preprocessor.get_feature_names_out())\n",
    "X_test_processed_df = pd.DataFrame(X_test_processed, columns=preprocessor.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3aa7e6c0-71f8-424c-97de-bffa00f59762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['num__sqm', 'num__sqft', 'num__airTemperature', 'num__cloudCoverage',\n",
       "       'num__dewTemperature', 'num__precipDepth1HR', 'num__precipDepth6HR',\n",
       "       'num__seaLvlPressure', 'num__windDirection', 'num__windSpeed',\n",
       "       'cat__timezone_Europe/Dublin', 'cat__timezone_Europe/London',\n",
       "       'cat__timezone_US/Eastern', 'cat__timezone_US/Mountain',\n",
       "       'cat__season_Fall', 'cat__season_Spring', 'cat__season_Summer',\n",
       "       'cat__season_Winter', 'cat__sub_primaryspaceusage_Academic',\n",
       "       'cat__sub_primaryspaceusage_Classroom',\n",
       "       'cat__sub_primaryspaceusage_College Classroom',\n",
       "       'cat__sub_primaryspaceusage_Primary/Secondary Classroom',\n",
       "       'cat__sub_primaryspaceusage_Research', 'cat__site_id_2',\n",
       "       'cat__site_id_9', 'cat__site_id_11', 'cat__site_id_15'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the columns\n",
    "X_train_processed_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12d6c076-8b37-4649-b894-f7c228ba616b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_scaled = np.log1p(y_train.values.reshape(-1, 1))\n",
    "y_test_scaled = np.log1p(y_test.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d738c7-c922-4e87-b1c0-cf68d155620b",
   "metadata": {},
   "source": [
    "### Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1aa0a7d7-d5b3-4a68-beea-bc0e5600640a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train_processed_df.shape[1], activation='relu')) # Adjust input_dim based on your features\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))  # Output layer, adjust units and activation based on your output\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a861e428-73d4-4d43-940a-b47c3e33633b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3660/3660 [==============================] - 1s 306us/step - loss: 9.1763\n",
      "Epoch 2/10\n",
      "3660/3660 [==============================] - 1s 303us/step - loss: 8.4047\n",
      "Epoch 3/10\n",
      "3660/3660 [==============================] - 1s 295us/step - loss: 7.8526\n",
      "Epoch 4/10\n",
      "3660/3660 [==============================] - 1s 296us/step - loss: 7.6339\n",
      "Epoch 5/10\n",
      "3660/3660 [==============================] - 1s 300us/step - loss: 7.5202\n",
      "Epoch 6/10\n",
      "3660/3660 [==============================] - 1s 295us/step - loss: 7.3880\n",
      "Epoch 7/10\n",
      "3660/3660 [==============================] - 1s 299us/step - loss: 7.3210\n",
      "Epoch 8/10\n",
      "3660/3660 [==============================] - 1s 295us/step - loss: 7.2094\n",
      "Epoch 9/10\n",
      "3660/3660 [==============================] - 1s 295us/step - loss: 7.1392\n",
      "Epoch 10/10\n",
      "3660/3660 [==============================] - 1s 293us/step - loss: 7.0592\n",
      "1144/1144 [==============================] - 0s 212us/step\n"
     ]
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "model.fit(X_train_processed, y_train_scaled, epochs=10, batch_size=10, verbose=1)\n",
    "\n",
    "# Predict the values for X_train\n",
    "y_pred = model.predict(X_train_processed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a63c9c65-7d26-46ac-b3a3-3c1ef9f511b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 6.920020025917805\n",
      "R-squared Score: 0.4397869655566857\n"
     ]
    }
   ],
   "source": [
    "#mae = mean_absolute_error(y_train_scaled, y_pred)\n",
    "mse = mean_squared_error(y_train_scaled, y_pred)\n",
    "r2 = r2_score(y_train_scaled, y_pred)\n",
    "\n",
    "#print('Mean Absolute Error:', mae)\n",
    "print('Mean Squared Error:', mse)\n",
    "print('R-squared Score:', r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b01b917-3f59-4110-b1c6-352fbdeeffe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1141/1141 [==============================] - 0s 212us/step\n",
      "Mean Squared Error: 12.053200983873037\n",
      "R-squared Score: 0.17413665786437782\n"
     ]
    }
   ],
   "source": [
    "# Predict the values for X_test\n",
    "y_pred = model.predict(X_test_processed_df)\n",
    "y_pred = np.nan_to_num(y_pred, nan=0)\n",
    "mse = mean_squared_error(y_test_scaled, y_pred)\n",
    "r2 = r2_score(y_test_scaled, y_pred)\n",
    "print('Mean Squared Error:', mse)\n",
    "print('R-squared Score:', r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7dc79f1c-a10c-4f82-bdfc-993b141e0dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from my_dir/quick_tune/tuner0.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8x/wqmfhzdj59vcq2kqnk5_9pp40000gn/T/ipykernel_68860/214843204.py:1: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  import kerastuner as kt\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "129/129 [==============================] - 0s 1ms/step - loss: 27.4214 - mae: 4.4356 - mse: 27.4214 - val_loss: 54.0271 - val_mae: 6.8519 - val_mse: 54.0271\n",
      "Epoch 2/10\n",
      "129/129 [==============================] - 0s 875us/step - loss: 12.2223 - mae: 2.9292 - mse: 12.2223 - val_loss: 31.5023 - val_mae: 5.4046 - val_mse: 31.5023\n",
      "Epoch 3/10\n",
      "129/129 [==============================] - 0s 837us/step - loss: 9.4755 - mae: 2.5074 - mse: 9.4755 - val_loss: 27.6213 - val_mae: 5.0656 - val_mse: 27.6213\n",
      "Epoch 4/10\n",
      "129/129 [==============================] - 0s 855us/step - loss: 8.6373 - mae: 2.3787 - mse: 8.6373 - val_loss: 25.7506 - val_mae: 4.8789 - val_mse: 25.7506\n",
      "Epoch 5/10\n",
      "129/129 [==============================] - 0s 853us/step - loss: 8.2255 - mae: 2.3170 - mse: 8.2255 - val_loss: 25.0196 - val_mae: 4.8001 - val_mse: 25.0196\n",
      "Epoch 6/10\n",
      "129/129 [==============================] - 0s 837us/step - loss: 8.0009 - mae: 2.2733 - mse: 8.0009 - val_loss: 25.1547 - val_mae: 4.8150 - val_mse: 25.1547\n",
      "Epoch 7/10\n",
      "129/129 [==============================] - 0s 822us/step - loss: 7.8672 - mae: 2.2430 - mse: 7.8672 - val_loss: 25.5613 - val_mae: 4.8593 - val_mse: 25.5613\n",
      "Epoch 8/10\n",
      "129/129 [==============================] - 0s 816us/step - loss: 7.7883 - mae: 2.2255 - mse: 7.7883 - val_loss: 25.6504 - val_mae: 4.8689 - val_mse: 25.6504\n",
      "Epoch 9/10\n",
      "129/129 [==============================] - 0s 976us/step - loss: 7.7426 - mae: 2.2133 - mse: 7.7426 - val_loss: 26.2241 - val_mae: 4.9297 - val_mse: 26.2241\n",
      "Epoch 10/10\n",
      "129/129 [==============================] - 0s 1ms/step - loss: 7.7100 - mae: 2.2061 - mse: 7.7100 - val_loss: 26.5997 - val_mae: 4.9691 - val_mse: 26.5997\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Dense(\n",
    "        units=hp.Int('input_units', min_value=32, max_value=256, step=64),  # Reduced max value and increased step\n",
    "        activation='relu',\n",
    "        input_shape=(X_train_processed.shape[1],)\n",
    "    ))\n",
    "\n",
    "    # Reduced the maximum number of layers\n",
    "    for i in range(hp.Int('n_layers', 1, 3)):\n",
    "        model.add(layers.Dense(\n",
    "            units=hp.Int(f'layer_{i}_units', min_value=32, max_value=256, step=64),  # Simplify layers\n",
    "            activation='relu'\n",
    "        ))\n",
    "\n",
    "    model.add(layers.Dense(1)) \n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-3, 1e-4])),  # Simplified choices\n",
    "        loss='mse',  \n",
    "        metrics=['mae', 'mse'] \n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_mse', \n",
    "    max_trials=10,  \n",
    "    executions_per_trial=2,  \n",
    "    directory='my_dir',\n",
    "    project_name='quick_tune'\n",
    ")\n",
    "\n",
    "tuner.search(\n",
    "    X_train_processed_df, y_train_scaled,\n",
    "    epochs=5,  # Reduced number of epochs for tuning\n",
    "    validation_split=0.1,  # Adjust based on your dataset\n",
    "    batch_size=256  # Increased batch size for faster processing\n",
    ")\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# Build the model with the best hyperparameters and train it on the data\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(\n",
    "    X_train_processed_df, y_train_scaled,\n",
    "    epochs=10,  # You can increase this for the final model training\n",
    "    validation_split=0.1,  # Keep consistent with tuning phase or adjust as necessary\n",
    "    batch_size=256  # Set a fixed batch size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c42eba5-15c8-47a2-9f29-828bdc2202eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check and replace NaN values in the test features \n",
    "if X_test_processed_df.isna().any().any(): \n",
    "    X_test_processed_df = X_test_processed_df.fillna(0)  # Replace NaN with 0 \n",
    "\n",
    "# Check and replace NaN values in the test labels \n",
    "if np.isnan(y_test_scaled).any():  \n",
    "    y_test_scaled = np.nan_to_num(y_test_scaled)  # Replace NaN with 0 (default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2abe9091-b602-468b-96a2-f5ffc0b8154f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 369us/step - loss: 12.1281 - mae: 2.8839 - mse: 12.1281\n",
      "Test Loss: 12.12814712524414, Test MAE: 2.8838841915130615, Test MSE: 12.12814712524414\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_mae, test_mse = model.evaluate(X_test_processed_df, y_test_scaled, batch_size=256)\n",
    "print(f'Test Loss: {test_loss}, Test MAE: {test_mae}, Test MSE: {test_mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "75d1d4b5-f635-4a3e-9345-ee4c602202f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 333us/step\n",
      "R-squared Score: 0.16900147187044778\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_processed_df, batch_size=256)\n",
    "\n",
    "# Calculate R-squared score\n",
    "r_squared = r2_score(y_test_scaled, y_pred)\n",
    "print(f'R-squared Score: {r_squared}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
