{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ca6139f-8132-4b02-b725-b5908c648fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error,  r2_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import kerastuner as kt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "73f8853e-6d6a-4cf3-8cd7-ca8c9a5a7277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            building_name        meter        date  meter_reading site_name  \\\n",
      "0  Bear_education_Alfredo  electricity  2016-01-01         2.9050      Bear   \n",
      "1  Bear_education_Alfredo  electricity  2016-01-02         2.7700      Bear   \n",
      "2  Bear_education_Alfredo  electricity  2016-01-03         2.6725      Bear   \n",
      "3  Bear_education_Alfredo  electricity  2016-01-04         4.5650      Bear   \n",
      "4  Bear_education_Alfredo  electricity  2016-01-05         4.7825      Bear   \n",
      "\n",
      "  sub_primaryspaceusage    sqm    sqft    timezone  airTemperature  \\\n",
      "0             Education  609.8  6564.0  US/Pacific        5.246861   \n",
      "1             Education  609.8  6564.0  US/Pacific        5.993973   \n",
      "2             Education  609.8  6564.0  US/Pacific        5.660314   \n",
      "3             Education  609.8  6564.0  US/Pacific        5.048507   \n",
      "4             Education  609.8  6564.0  US/Pacific        4.745567   \n",
      "\n",
      "   cloudCoverage  dewTemperature  precipDepth1HR  precipDepth6HR  \\\n",
      "0       1.927009        0.254484        0.351088       10.801125   \n",
      "1       1.997893        0.892188        0.409453       11.105558   \n",
      "2       1.946017        0.778475        0.552568       11.167389   \n",
      "3       1.987616       -0.268905        0.479493       11.089874   \n",
      "4       2.007311        0.321921        1.033857       11.723586   \n",
      "\n",
      "   seaLvlPressure  windDirection  windSpeed  season  building_id  site_id  \n",
      "0     1018.888301     172.924863   3.807399  Winter            1        1  \n",
      "1     1014.347411     181.359441   4.202455  Winter            1        1  \n",
      "2     1010.396019     208.978674   4.015919  Winter            1        1  \n",
      "3     1008.903334     211.377040   3.909701  Winter            1        1  \n",
      "4     1012.747700     170.002007   3.528571  Winter            1        1  \n",
      "            building_name        meter        date  meter_reading site_name  \\\n",
      "0  Bear_education_Alfredo  electricity  2017-01-01         2.1775      Bear   \n",
      "1  Bear_education_Alfredo  electricity  2017-01-02         2.7925      Bear   \n",
      "2  Bear_education_Alfredo  electricity  2017-01-03         7.1100      Bear   \n",
      "3  Bear_education_Alfredo  electricity  2017-01-04         6.8450      Bear   \n",
      "4  Bear_education_Alfredo  electricity  2017-01-05         3.9500      Bear   \n",
      "\n",
      "  sub_primaryspaceusage    sqm    sqft    timezone  airTemperature  \\\n",
      "0             Education  609.8  6564.0  US/Pacific        6.313140   \n",
      "1             Education  609.8  6564.0  US/Pacific        5.297363   \n",
      "2             Education  609.8  6564.0  US/Pacific        5.970330   \n",
      "3             Education  609.8  6564.0  US/Pacific        5.959649   \n",
      "4             Education  609.8  6564.0  US/Pacific        1.717660   \n",
      "\n",
      "   cloudCoverage  dewTemperature  precipDepth1HR  precipDepth6HR  \\\n",
      "0       2.126542        1.751662        0.414432       11.077130   \n",
      "1       1.923200        2.274505        0.930626       11.221247   \n",
      "2       2.180302        3.279560        2.242145       12.169223   \n",
      "3       2.309525        1.680482        1.715769       12.168157   \n",
      "4       2.071431       -3.608609        0.294415       10.758541   \n",
      "\n",
      "   seaLvlPressure  windDirection  windSpeed  season  building_id  site_id  \n",
      "0     1017.729660     167.173422   3.224944  Winter            1        1  \n",
      "1     1023.168730     128.275621   3.071918  Winter            1        1  \n",
      "2     1017.886469     178.171787   3.910330  Winter            1        1  \n",
      "3     1013.028823     243.891423   3.783333  Winter            1        1  \n",
      "4     1018.172131     207.449203   2.771794  Winter            1        1  \n"
     ]
    }
   ],
   "source": [
    "# Loading the dataset\n",
    "# Train Data\n",
    "temp_df = pd.read_csv(\"../../data/cleaned/train.csv\", nrows=0)  # Read only the header\n",
    "total_columns = len(temp_df.columns)\n",
    "columns_to_use = temp_df.columns[1:total_columns]\n",
    "train_data = pd.read_csv(\"../../data/cleaned/train.csv\",  usecols=columns_to_use)\n",
    "print(train_data.head(5))\n",
    "# Test Data\n",
    "test_data = pd.read_csv(\"../../data/cleaned/test.csv\", usecols=columns_to_use)\n",
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "80666069-c818-4a0c-b571-994016202bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['electricity', 'chilledwater', 'gas', 'hotwater', 'solar', 'water',\n",
       "       'steam', 'irrigation'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['meter'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a35fbac5-5d84-4b88-adf8-fb13549d2bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the columns that are not relevant to our analysis\n",
    "train_data = train_data.drop(columns=['building_name', 'site_name'])\n",
    "test_data = test_data.drop(columns=['building_name', 'site_name'])\n",
    "\n",
    "train_data = train_data[(train_data['meter'] == 'electricity') | (train_data['meter'] == 'chilledwater') | (train_data['meter'] == 'steam')\n",
    "| (train_data['meter'] == 'hotwater') | (train_data['meter'] == 'gas')]\n",
    "\n",
    "test_data = test_data[(test_data['meter'] == 'electricity') | (test_data['meter'] == 'chilledwater') | (test_data['meter'] == 'steam')\n",
    "| (test_data['meter'] == 'hotwater') | (test_data['meter'] == 'gas')]\n",
    "\n",
    "# Building index on building_id for further assessment\n",
    "train_data.set_index('building_id', inplace=True)\n",
    "test_data.set_index('building_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "609ef3da-792c-4ef5-a954-9bd0b3c4f7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering for hotwater meter_reading\n",
    "train_data = train_data[train_data['meter'] == 'hotwater']\n",
    "test_data = test_data[test_data['meter'] == 'hotwater']\n",
    "\n",
    "train_data = train_data.drop(columns=['meter'])\n",
    "test_data = test_data.drop(columns=['meter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a0b4676f-eb9c-4e03-a002-115dbfe3349f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   date  meter_reading sub_primaryspaceusage      sqm  \\\n",
      "building_id                                                             \n",
      "584          2016-09-07          0.000    College Laboratory   2992.0   \n",
      "78           2016-04-29        492.697              Academic  16116.7   \n",
      "\n",
      "                 sqft       timezone  airTemperature  cloudCoverage  \\\n",
      "building_id                                                           \n",
      "584           32206.0  Europe/London       23.652193       1.860015   \n",
      "78           173479.0    US/Mountain       12.281978       2.105182   \n",
      "\n",
      "             dewTemperature  precipDepth1HR  precipDepth6HR  seaLvlPressure  \\\n",
      "building_id                                                                   \n",
      "584               16.769737        1.202212       11.328716     1015.793681   \n",
      "78                 5.268132        0.406701       12.112282     1014.526752   \n",
      "\n",
      "             windDirection  windSpeed  season  site_id  \n",
      "building_id                                             \n",
      "584             153.607061   2.759493    Fall       14  \n",
      "78              166.361744   3.798260  Spring        2  \n",
      "-------------------------------------------------------------\n",
      "                   date  meter_reading sub_primaryspaceusage     sqm     sqft  \\\n",
      "building_id                                                                     \n",
      "227          2017-07-05         0.0000     College Classroom   864.8   9309.0   \n",
      "84           2017-02-15       296.0379              Academic  2033.8  21892.0   \n",
      "\n",
      "                timezone  airTemperature  cloudCoverage  dewTemperature  \\\n",
      "building_id                                                               \n",
      "227          US/Mountain       23.943736       1.872254       14.932527   \n",
      "84           US/Mountain        8.155263       1.966024        2.782886   \n",
      "\n",
      "             precipDepth1HR  precipDepth6HR  seaLvlPressure  windDirection  \\\n",
      "building_id                                                                  \n",
      "227                0.963725       17.215911     1017.617343     166.049376   \n",
      "84                 0.685704       11.343410     1013.382465     185.771459   \n",
      "\n",
      "             windSpeed  season  site_id  \n",
      "building_id                              \n",
      "227           2.838901  Summer        7  \n",
      "84            3.834211  Winter        2  \n"
     ]
    }
   ],
   "source": [
    "# Inspecting the data frames\n",
    "print(train_data.sample(2))\n",
    "print('-------------------------------------------------------------')\n",
    "print(test_data.sample(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "75abc748-d8bf-4b49-815d-979cba143f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating into X and Y dataframes\n",
    "X_train = train_data.drop(columns=['meter_reading'])  # Exclude target variable\n",
    "y_train = train_data['meter_reading']\n",
    "\n",
    "X_test = test_data.drop(columns=['meter_reading'])  # Exclude target variable\n",
    "y_test = test_data['meter_reading']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f6c0c0cd-43ef-427d-97ba-d5c31aacf747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'site_id' from numeric to categorical\n",
    "X_train['site_id'] = X_train['site_id'].astype('category')\n",
    "X_test['site_id'] = X_test['site_id'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f1cc3382-f4df-4e09-a935-93306c5e3eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date                       object\n",
      "sub_primaryspaceusage      object\n",
      "sqm                       float64\n",
      "sqft                      float64\n",
      "timezone                   object\n",
      "airTemperature            float64\n",
      "cloudCoverage             float64\n",
      "dewTemperature            float64\n",
      "precipDepth1HR            float64\n",
      "precipDepth6HR            float64\n",
      "seaLvlPressure            float64\n",
      "windDirection             float64\n",
      "windSpeed                 float64\n",
      "season                     object\n",
      "site_id                  category\n",
      "dtype: object\n",
      "Index(['date', 'sub_primaryspaceusage', 'sqm', 'sqft', 'timezone',\n",
      "       'airTemperature', 'cloudCoverage', 'dewTemperature', 'precipDepth1HR',\n",
      "       'precipDepth6HR', 'seaLvlPressure', 'windDirection', 'windSpeed',\n",
      "       'season', 'site_id'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(X_train.dtypes)\n",
    "print(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "26481f29-0b4f-42b8-8b02-89086982432f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and types based on your dataset\n",
    "numerical_features = ['sqm', 'sqft', 'airTemperature', 'cloudCoverage', 'dewTemperature',\n",
    "                      'precipDepth1HR', 'precipDepth6HR', 'seaLvlPressure', 'windDirection', 'windSpeed']\n",
    "categorical_features = ['timezone', 'season', 'sub_primaryspaceusage', 'site_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "08132472-5878-49eb-be6a-157a7f8a8f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', MinMaxScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8d3d2e20-1a12-420d-a7db-4f6e7ab4de8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', MinMaxScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Fit the preprocessor on the training data and transform both training and test data\n",
    "preprocessor.fit(X_train)\n",
    "X_train_processed = preprocessor.transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eae425e1-383d-4d28-956b-ee768b111a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the processed data back to dense DataFrames\n",
    "X_train_processed_df = pd.DataFrame(X_train_processed, columns=preprocessor.get_feature_names_out())\n",
    "X_test_processed_df = pd.DataFrame(X_test_processed, columns=preprocessor.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3aa7e6c0-71f8-424c-97de-bffa00f59762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['num__sqm', 'num__sqft', 'num__airTemperature', 'num__cloudCoverage',\n",
       "       'num__dewTemperature', 'num__precipDepth1HR', 'num__precipDepth6HR',\n",
       "       'num__seaLvlPressure', 'num__windDirection', 'num__windSpeed',\n",
       "       'cat__timezone_Europe/London', 'cat__timezone_US/Eastern',\n",
       "       'cat__timezone_US/Mountain', 'cat__season_Fall', 'cat__season_Spring',\n",
       "       'cat__season_Summer', 'cat__season_Winter',\n",
       "       'cat__sub_primaryspaceusage_Academic',\n",
       "       'cat__sub_primaryspaceusage_Classroom',\n",
       "       'cat__sub_primaryspaceusage_College Classroom',\n",
       "       'cat__sub_primaryspaceusage_College Laboratory',\n",
       "       'cat__sub_primaryspaceusage_Research',\n",
       "       'cat__sub_primaryspaceusage_Student Center',\n",
       "       'cat__sub_primaryspaceusage_Student Union', 'cat__site_id_2',\n",
       "       'cat__site_id_4', 'cat__site_id_5', 'cat__site_id_6', 'cat__site_id_7',\n",
       "       'cat__site_id_10', 'cat__site_id_14'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the columns\n",
    "X_train_processed_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "12d6c076-8b37-4649-b894-f7c228ba616b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_scaled = np.log1p(y_train.values.reshape(-1, 1))\n",
    "y_test_scaled = np.log1p(y_test.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d738c7-c922-4e87-b1c0-cf68d155620b",
   "metadata": {},
   "source": [
    "### Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1aa0a7d7-d5b3-4a68-beea-bc0e5600640a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train_processed_df.shape[1], activation='relu')) # Adjust input_dim based on your features\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))  # Output layer, adjust units and activation based on your output\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a861e428-73d4-4d43-940a-b47c3e33633b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2965/2965 [==============================] - 1s 322us/step - loss: 19.4507\n",
      "Epoch 2/10\n",
      "2965/2965 [==============================] - 1s 313us/step - loss: 17.1027\n",
      "Epoch 3/10\n",
      "2965/2965 [==============================] - 1s 306us/step - loss: 16.4448\n",
      "Epoch 4/10\n",
      "2965/2965 [==============================] - 1s 310us/step - loss: 15.8546\n",
      "Epoch 5/10\n",
      "2965/2965 [==============================] - 1s 309us/step - loss: 15.1307\n",
      "Epoch 6/10\n",
      "2965/2965 [==============================] - 1s 310us/step - loss: 14.5777\n",
      "Epoch 7/10\n",
      "2965/2965 [==============================] - 1s 313us/step - loss: 14.1444\n",
      "Epoch 8/10\n",
      "2965/2965 [==============================] - 1s 322us/step - loss: 13.8370\n",
      "Epoch 9/10\n",
      "2965/2965 [==============================] - 1s 308us/step - loss: 13.5134\n",
      "Epoch 10/10\n",
      "2965/2965 [==============================] - 1s 307us/step - loss: 13.2049\n",
      "927/927 [==============================] - 0s 211us/step\n"
     ]
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "model.fit(X_train_processed, y_train_scaled, epochs=10, batch_size=10, verbose=1)\n",
    "\n",
    "# Predict the values for X_train\n",
    "y_pred = model.predict(X_train_processed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a63c9c65-7d26-46ac-b3a3-3c1ef9f511b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 13.303919684359082\n",
      "R-squared Score: 0.5726096069162547\n"
     ]
    }
   ],
   "source": [
    "#mae = mean_absolute_error(y_train_scaled, y_pred)\n",
    "mse = mean_squared_error(y_train_scaled, y_pred)\n",
    "r2 = r2_score(y_train_scaled, y_pred)\n",
    "\n",
    "#print('Mean Absolute Error:', mae)\n",
    "print('Mean Squared Error:', mse)\n",
    "print('R-squared Score:', r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5b01b917-3f59-4110-b1c6-352fbdeeffe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "924/924 [==============================] - 0s 223us/step\n",
      "Mean Squared Error: 18.02956578787283\n",
      "R-squared Score: 0.4691722820386899\n"
     ]
    }
   ],
   "source": [
    "# Predict the values for X_test\n",
    "y_pred = model.predict(X_test_processed_df)\n",
    "y_pred = np.nan_to_num(y_pred, nan=0)\n",
    "mse = mean_squared_error(y_test_scaled, y_pred)\n",
    "r2 = r2_score(y_test_scaled, y_pred)\n",
    "print('Mean Squared Error:', mse)\n",
    "print('R-squared Score:', r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7dc79f1c-a10c-4f82-bdfc-993b141e0dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from my_dir/quick_tune/tuner0.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 79.9790 - mae: 7.3676 - mse: 79.9790 - val_loss: 29.8135 - val_mae: 5.0782 - val_mse: 29.8135\n",
      "Epoch 2/10\n",
      "105/105 [==============================] - 0s 847us/step - loss: 46.9201 - mae: 6.0950 - mse: 46.9201 - val_loss: 15.0704 - val_mae: 3.6573 - val_mse: 15.0704\n",
      "Epoch 3/10\n",
      "105/105 [==============================] - 0s 829us/step - loss: 29.7073 - mae: 4.9044 - mse: 29.7073 - val_loss: 14.2035 - val_mae: 3.5895 - val_mse: 14.2035\n",
      "Epoch 4/10\n",
      "105/105 [==============================] - 0s 827us/step - loss: 24.1773 - mae: 4.2865 - mse: 24.1773 - val_loss: 17.3283 - val_mae: 3.9551 - val_mse: 17.3283\n",
      "Epoch 5/10\n",
      "105/105 [==============================] - 0s 830us/step - loss: 21.6298 - mae: 3.8747 - mse: 21.6298 - val_loss: 22.1526 - val_mae: 4.3887 - val_mse: 22.1526\n",
      "Epoch 6/10\n",
      "105/105 [==============================] - 0s 814us/step - loss: 20.7758 - mae: 3.6920 - mse: 20.7758 - val_loss: 26.3128 - val_mae: 4.7338 - val_mse: 26.3128\n",
      "Epoch 7/10\n",
      "105/105 [==============================] - 0s 872us/step - loss: 20.4413 - mae: 3.5956 - mse: 20.4413 - val_loss: 30.4248 - val_mae: 5.0589 - val_mse: 30.4248\n",
      "Epoch 8/10\n",
      "105/105 [==============================] - 0s 859us/step - loss: 20.2292 - mae: 3.5660 - mse: 20.2292 - val_loss: 33.7952 - val_mae: 5.3055 - val_mse: 33.7952\n",
      "Epoch 9/10\n",
      "105/105 [==============================] - 0s 828us/step - loss: 20.0674 - mae: 3.5420 - mse: 20.0674 - val_loss: 37.0673 - val_mae: 5.5395 - val_mse: 37.0673\n",
      "Epoch 10/10\n",
      "105/105 [==============================] - 0s 829us/step - loss: 19.9253 - mae: 3.5169 - mse: 19.9253 - val_loss: 39.3555 - val_mae: 5.7082 - val_mse: 39.3555\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Dense(\n",
    "        units=hp.Int('input_units', min_value=32, max_value=256, step=64),  # Reduced max value and increased step\n",
    "        activation='relu',\n",
    "        input_shape=(X_train_processed.shape[1],)\n",
    "    ))\n",
    "\n",
    "    # Reduced the maximum number of layers\n",
    "    for i in range(hp.Int('n_layers', 1, 3)):\n",
    "        model.add(layers.Dense(\n",
    "            units=hp.Int(f'layer_{i}_units', min_value=32, max_value=256, step=64),  # Simplify layers\n",
    "            activation='relu'\n",
    "        ))\n",
    "\n",
    "    model.add(layers.Dense(1)) \n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-3, 1e-4])),  # Simplified choices\n",
    "        loss='mse',  \n",
    "        metrics=['mae', 'mse'] \n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_mse', \n",
    "    max_trials=10,  \n",
    "    executions_per_trial=2,  \n",
    "    directory='my_dir',\n",
    "    project_name='quick_tune'\n",
    ")\n",
    "\n",
    "tuner.search(\n",
    "    X_train_processed_df, y_train_scaled,\n",
    "    epochs=5,  # Reduced number of epochs for tuning\n",
    "    validation_split=0.1,  # Adjust based on your dataset\n",
    "    batch_size=256  # Increased batch size for faster processing\n",
    ")\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# Build the model with the best hyperparameters and train it on the data\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(\n",
    "    X_train_processed_df, y_train_scaled,\n",
    "    epochs=10,  # You can increase this for the final model training\n",
    "    validation_split=0.1,  # Keep consistent with tuning phase or adjust as necessary\n",
    "    batch_size=256  # Set a fixed batch size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2c42eba5-15c8-47a2-9f29-828bdc2202eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check and replace NaN values in the test features \n",
    "if X_test_processed_df.isna().any().any(): \n",
    "    X_test_processed_df = X_test_processed_df.fillna(0)  # Replace NaN with 0 \n",
    "\n",
    "# Check and replace NaN values in the test labels \n",
    "if np.isnan(y_test_scaled).any():  \n",
    "    y_test_scaled = np.nan_to_num(y_test_scaled)  # Replace NaN with 0 (default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2abe9091-b602-468b-96a2-f5ffc0b8154f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 0s 374us/step - loss: 21.4778 - mae: 3.7687 - mse: 21.4778\n",
      "Test Loss: 21.477813720703125, Test MAE: 3.768683671951294, Test MSE: 21.477813720703125\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_mae, test_mse = model.evaluate(X_test_processed_df, y_test_scaled, batch_size=256)\n",
    "print(f'Test Loss: {test_loss}, Test MAE: {test_mae}, Test MSE: {test_mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "75d1d4b5-f635-4a3e-9345-ee4c602202f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 0s 342us/step\n",
      "R-squared Score: 0.36764879776502923\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_processed_df, batch_size=256)\n",
    "\n",
    "# Calculate R-squared score\n",
    "r_squared = r2_score(y_test_scaled, y_pred)\n",
    "print(f'R-squared Score: {r_squared}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
