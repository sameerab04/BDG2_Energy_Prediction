{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ca6139f-8132-4b02-b725-b5908c648fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error,  r2_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "import kerastuner as kt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73f8853e-6d6a-4cf3-8cd7-ca8c9a5a7277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            building_name        meter        date  meter_reading site_name  \\\n",
      "0  Bear_education_Alfredo  electricity  2016-01-01         2.9050      Bear   \n",
      "1  Bear_education_Alfredo  electricity  2016-01-02         2.7700      Bear   \n",
      "2  Bear_education_Alfredo  electricity  2016-01-03         2.6725      Bear   \n",
      "3  Bear_education_Alfredo  electricity  2016-01-04         4.5650      Bear   \n",
      "4  Bear_education_Alfredo  electricity  2016-01-05         4.7825      Bear   \n",
      "\n",
      "  sub_primaryspaceusage    sqm    sqft    timezone  airTemperature  \\\n",
      "0             Education  609.8  6564.0  US/Pacific        5.246861   \n",
      "1             Education  609.8  6564.0  US/Pacific        5.993973   \n",
      "2             Education  609.8  6564.0  US/Pacific        5.660314   \n",
      "3             Education  609.8  6564.0  US/Pacific        5.048507   \n",
      "4             Education  609.8  6564.0  US/Pacific        4.745567   \n",
      "\n",
      "   cloudCoverage  dewTemperature  precipDepth1HR  precipDepth6HR  \\\n",
      "0       1.927009        0.254484        0.351088       10.801125   \n",
      "1       1.997893        0.892188        0.409453       11.105558   \n",
      "2       1.946017        0.778475        0.552568       11.167389   \n",
      "3       1.987616       -0.268905        0.479493       11.089874   \n",
      "4       2.007311        0.321921        1.033857       11.723586   \n",
      "\n",
      "   seaLvlPressure  windDirection  windSpeed  season  building_id  site_id  \n",
      "0     1018.888301     172.924863   3.807399  Winter            1        1  \n",
      "1     1014.347411     181.359441   4.202455  Winter            1        1  \n",
      "2     1010.396019     208.978674   4.015919  Winter            1        1  \n",
      "3     1008.903334     211.377040   3.909701  Winter            1        1  \n",
      "4     1012.747700     170.002007   3.528571  Winter            1        1  \n",
      "            building_name        meter        date  meter_reading site_name  \\\n",
      "0  Bear_education_Alfredo  electricity  2017-01-01         2.1775      Bear   \n",
      "1  Bear_education_Alfredo  electricity  2017-01-02         2.7925      Bear   \n",
      "2  Bear_education_Alfredo  electricity  2017-01-03         7.1100      Bear   \n",
      "3  Bear_education_Alfredo  electricity  2017-01-04         6.8450      Bear   \n",
      "4  Bear_education_Alfredo  electricity  2017-01-05         3.9500      Bear   \n",
      "\n",
      "  sub_primaryspaceusage    sqm    sqft    timezone  airTemperature  \\\n",
      "0             Education  609.8  6564.0  US/Pacific        6.313140   \n",
      "1             Education  609.8  6564.0  US/Pacific        5.297363   \n",
      "2             Education  609.8  6564.0  US/Pacific        5.970330   \n",
      "3             Education  609.8  6564.0  US/Pacific        5.959649   \n",
      "4             Education  609.8  6564.0  US/Pacific        1.717660   \n",
      "\n",
      "   cloudCoverage  dewTemperature  precipDepth1HR  precipDepth6HR  \\\n",
      "0       2.126542        1.751662        0.414432       11.077130   \n",
      "1       1.923200        2.274505        0.930626       11.221247   \n",
      "2       2.180302        3.279560        2.242145       12.169223   \n",
      "3       2.309525        1.680482        1.715769       12.168157   \n",
      "4       2.071431       -3.608609        0.294415       10.758541   \n",
      "\n",
      "   seaLvlPressure  windDirection  windSpeed  season  building_id  site_id  \n",
      "0     1017.729660     167.173422   3.224944  Winter            1        1  \n",
      "1     1023.168730     128.275621   3.071918  Winter            1        1  \n",
      "2     1017.886469     178.171787   3.910330  Winter            1        1  \n",
      "3     1013.028823     243.891423   3.783333  Winter            1        1  \n",
      "4     1018.172131     207.449203   2.771794  Winter            1        1  \n"
     ]
    }
   ],
   "source": [
    "# Loading the dataset\n",
    "# Train Data\n",
    "temp_df = pd.read_csv(\"../../data/cleaned/train.csv\", nrows=0)  # Read only the header\n",
    "total_columns = len(temp_df.columns)\n",
    "columns_to_use = temp_df.columns[1:total_columns]\n",
    "train_data = pd.read_csv(\"../../data/cleaned/train.csv\",  usecols=columns_to_use)\n",
    "print(train_data.head(5))\n",
    "# Test Data\n",
    "test_data = pd.read_csv(\"../../data/cleaned/test.csv\", usecols=columns_to_use)\n",
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80666069-c818-4a0c-b571-994016202bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['electricity', 'chilledwater', 'gas', 'hotwater', 'solar', 'water',\n",
       "       'steam', 'irrigation'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['meter'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a35fbac5-5d84-4b88-adf8-fb13549d2bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the columns that are not relevant to our analysis\n",
    "train_data = train_data.drop(columns=['building_name', 'site_name'])\n",
    "test_data = test_data.drop(columns=['building_name', 'site_name'])\n",
    "\n",
    "train_data = train_data[(train_data['meter'] == 'electricity') | (train_data['meter'] == 'chilledwater') | (train_data['meter'] == 'steam')\n",
    "| (train_data['meter'] == 'hotwater') | (train_data['meter'] == 'gas')]\n",
    "\n",
    "test_data = test_data[(test_data['meter'] == 'electricity') | (test_data['meter'] == 'chilledwater') | (test_data['meter'] == 'steam')\n",
    "| (test_data['meter'] == 'hotwater') | (test_data['meter'] == 'gas')]\n",
    "\n",
    "# Building index on building_id for further assessment\n",
    "train_data.set_index('building_id', inplace=True)\n",
    "test_data.set_index('building_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "609ef3da-792c-4ef5-a954-9bd0b3c4f7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering for chilledwater meter_reading\n",
    "train_data = train_data[train_data['meter'] == 'chilledwater']\n",
    "test_data = test_data[test_data['meter'] == 'chilledwater']\n",
    "\n",
    "train_data = train_data.drop(columns=['meter'])\n",
    "test_data = test_data.drop(columns=['meter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0b4676f-eb9c-4e03-a002-115dbfe3349f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   date  meter_reading        sub_primaryspaceusage     sqm  \\\n",
      "building_id                                                                   \n",
      "333          2016-09-21        258.952  Primary/Secondary Classroom  1303.0   \n",
      "359          2016-04-21        540.328  Primary/Secondary Classroom  1589.0   \n",
      "\n",
      "                sqft       timezone  airTemperature  cloudCoverage  \\\n",
      "building_id                                                          \n",
      "333          14025.0  Europe/London       21.088444       1.901505   \n",
      "359          17104.0  Europe/London       16.017544       2.015152   \n",
      "\n",
      "             dewTemperature  precipDepth1HR  precipDepth6HR  seaLvlPressure  \\\n",
      "building_id                                                                   \n",
      "333               14.477556        0.822340       11.204068     1016.495014   \n",
      "359                5.913158        0.705059       12.623973     1016.749204   \n",
      "\n",
      "             windDirection  windSpeed  season  site_id  \n",
      "building_id                                             \n",
      "333             141.689448   3.198444    Fall        9  \n",
      "359             134.419945   3.959886  Spring        9  \n",
      "-------------------------------------------------------------\n",
      "                   date  meter_reading        sub_primaryspaceusage     sqm  \\\n",
      "building_id                                                                   \n",
      "337          2017-11-01       1308.411  Primary/Secondary Classroom  9005.0   \n",
      "376          2017-10-21         42.531  Primary/Secondary Classroom  1014.0   \n",
      "\n",
      "                sqft       timezone  airTemperature  cloudCoverage  \\\n",
      "building_id                                                          \n",
      "337          96929.0  Europe/London       11.350000       1.862638   \n",
      "376          10915.0  Europe/London       16.199561       1.828138   \n",
      "\n",
      "             dewTemperature  precipDepth1HR  precipDepth6HR  seaLvlPressure  \\\n",
      "building_id                                                                   \n",
      "337                6.850658        0.839251       11.545137     1017.942110   \n",
      "376                9.858553        0.594560       11.545137     1016.028075   \n",
      "\n",
      "             windDirection  windSpeed season  site_id  \n",
      "building_id                                            \n",
      "337             150.738041   2.628289   Fall        9  \n",
      "376             169.632753   4.401535   Fall        9  \n"
     ]
    }
   ],
   "source": [
    "# Inspecting the data frames\n",
    "print(train_data.sample(2))\n",
    "print('-------------------------------------------------------------')\n",
    "print(test_data.sample(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75abc748-d8bf-4b49-815d-979cba143f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating into X and Y dataframes\n",
    "X_train = train_data.drop(columns=['meter_reading'])  # Exclude target variable\n",
    "y_train = train_data['meter_reading']\n",
    "\n",
    "X_test = test_data.drop(columns=['meter_reading'])  # Exclude target variable\n",
    "y_test = test_data['meter_reading']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6c0c0cd-43ef-427d-97ba-d5c31aacf747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'site_id' from numeric to categorical\n",
    "X_train['site_id'] = X_train['site_id'].astype('category')\n",
    "X_test['site_id'] = X_test['site_id'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1cc3382-f4df-4e09-a935-93306c5e3eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date                       object\n",
      "sub_primaryspaceusage      object\n",
      "sqm                       float64\n",
      "sqft                      float64\n",
      "timezone                   object\n",
      "airTemperature            float64\n",
      "cloudCoverage             float64\n",
      "dewTemperature            float64\n",
      "precipDepth1HR            float64\n",
      "precipDepth6HR            float64\n",
      "seaLvlPressure            float64\n",
      "windDirection             float64\n",
      "windSpeed                 float64\n",
      "season                     object\n",
      "site_id                  category\n",
      "dtype: object\n",
      "Index(['date', 'sub_primaryspaceusage', 'sqm', 'sqft', 'timezone',\n",
      "       'airTemperature', 'cloudCoverage', 'dewTemperature', 'precipDepth1HR',\n",
      "       'precipDepth6HR', 'seaLvlPressure', 'windDirection', 'windSpeed',\n",
      "       'season', 'site_id'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(X_train.dtypes)\n",
    "print(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26481f29-0b4f-42b8-8b02-89086982432f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and types based on your dataset\n",
    "numerical_features = ['sqm', 'sqft', 'airTemperature', 'cloudCoverage', 'dewTemperature',\n",
    "                      'precipDepth1HR', 'precipDepth6HR', 'seaLvlPressure', 'windDirection', 'windSpeed']\n",
    "categorical_features = ['timezone', 'season', 'sub_primaryspaceusage', 'site_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08132472-5878-49eb-be6a-157a7f8a8f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', MinMaxScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d3d2e20-1a12-420d-a7db-4f6e7ab4de8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', MinMaxScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Fit the preprocessor on the training data and transform both training and test data\n",
    "preprocessor.fit(X_train)\n",
    "X_train_processed = preprocessor.transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eae425e1-383d-4d28-956b-ee768b111a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the processed data back to dense DataFrames\n",
    "X_train_processed_df = pd.DataFrame(X_train_processed, columns=preprocessor.get_feature_names_out())\n",
    "X_test_processed_df = pd.DataFrame(X_test_processed, columns=preprocessor.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3aa7e6c0-71f8-424c-97de-bffa00f59762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['num__sqm', 'num__sqft', 'num__airTemperature', 'num__cloudCoverage',\n",
       "       'num__dewTemperature', 'num__precipDepth1HR', 'num__precipDepth6HR',\n",
       "       'num__seaLvlPressure', 'num__windDirection', 'num__windSpeed',\n",
       "       'cat__timezone_Europe/Dublin', 'cat__timezone_Europe/London',\n",
       "       'cat__timezone_US/Eastern', 'cat__timezone_US/Mountain',\n",
       "       'cat__season_Fall', 'cat__season_Spring', 'cat__season_Summer',\n",
       "       'cat__season_Winter', 'cat__sub_primaryspaceusage_Academic',\n",
       "       'cat__sub_primaryspaceusage_Classroom',\n",
       "       'cat__sub_primaryspaceusage_College Classroom',\n",
       "       'cat__sub_primaryspaceusage_Primary/Secondary Classroom',\n",
       "       'cat__sub_primaryspaceusage_Research', 'cat__site_id_2',\n",
       "       'cat__site_id_9', 'cat__site_id_11', 'cat__site_id_15'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the columns\n",
    "X_train_processed_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12d6c076-8b37-4649-b894-f7c228ba616b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_scaled = np.log1p(y_train.values.reshape(-1, 1))\n",
    "y_test_scaled = np.log1p(y_test.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d738c7-c922-4e87-b1c0-cf68d155620b",
   "metadata": {},
   "source": [
    "### Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1aa0a7d7-d5b3-4a68-beea-bc0e5600640a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train_processed_df.shape[1], activation='relu')) # Adjust input_dim based on your features\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))  # Output layer, adjust units and activation based on your output\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a861e428-73d4-4d43-940a-b47c3e33633b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3660/3660 [==============================] - 1s 299us/step - loss: 9.2042\n",
      "Epoch 2/10\n",
      "3660/3660 [==============================] - 1s 297us/step - loss: 8.4842\n",
      "Epoch 3/10\n",
      "3660/3660 [==============================] - 1s 295us/step - loss: 7.9942\n",
      "Epoch 4/10\n",
      "3660/3660 [==============================] - 1s 304us/step - loss: 7.7841\n",
      "Epoch 5/10\n",
      "3660/3660 [==============================] - 1s 300us/step - loss: 7.6216\n",
      "Epoch 6/10\n",
      "3660/3660 [==============================] - 1s 299us/step - loss: 7.4727\n",
      "Epoch 7/10\n",
      "3660/3660 [==============================] - 1s 296us/step - loss: 7.3236\n",
      "Epoch 8/10\n",
      "3660/3660 [==============================] - 1s 295us/step - loss: 7.1893\n",
      "Epoch 9/10\n",
      "3660/3660 [==============================] - 1s 294us/step - loss: 7.0201\n",
      "Epoch 10/10\n",
      "3660/3660 [==============================] - 1s 300us/step - loss: 6.9244\n",
      "1144/1144 [==============================] - 0s 212us/step\n"
     ]
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "model.fit(X_train_processed, y_train_scaled, epochs=10, batch_size=10, verbose=1)\n",
    "\n",
    "# Predict the values for X_train\n",
    "y_pred = model.predict(X_train_processed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a63c9c65-7d26-46ac-b3a3-3c1ef9f511b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 6.871198654997356\n",
      "R-squared Score: 0.4437393194872512\n"
     ]
    }
   ],
   "source": [
    "#mae = mean_absolute_error(y_train_scaled, y_pred)\n",
    "mse = mean_squared_error(y_train_scaled, y_pred)\n",
    "r2 = r2_score(y_train_scaled, y_pred)\n",
    "\n",
    "#print('Mean Absolute Error:', mae)\n",
    "print('Mean Squared Error:', mse)\n",
    "print('R-squared Score:', r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b01b917-3f59-4110-b1c6-352fbdeeffe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1141/1141 [==============================] - 0s 216us/step\n",
      "Mean Squared Error: 11.390680619580609\n",
      "R-squared Score: 0.2195313445554513\n"
     ]
    }
   ],
   "source": [
    "# Predict the values for X_test\n",
    "y_pred = model.predict(X_test_processed_df)\n",
    "y_pred = np.nan_to_num(y_pred, nan=0)\n",
    "mse = mean_squared_error(y_test_scaled, y_pred)\n",
    "r2 = r2_score(y_test_scaled, y_pred)\n",
    "print('Mean Squared Error:', mse)\n",
    "print('R-squared Score:', r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7dc79f1c-a10c-4f82-bdfc-993b141e0dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from my_dir/quick_tune/tuner0.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8x/wqmfhzdj59vcq2kqnk5_9pp40000gn/T/ipykernel_68922/214843204.py:1: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  import kerastuner as kt\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "129/129 [==============================] - 0s 1ms/step - loss: 24.0268 - mae: 4.1399 - mse: 24.0268 - val_loss: 48.6014 - val_mae: 6.5641 - val_mse: 48.6014\n",
      "Epoch 2/10\n",
      "129/129 [==============================] - 0s 857us/step - loss: 11.1620 - mae: 2.7208 - mse: 11.1620 - val_loss: 31.8590 - val_mae: 5.4395 - val_mse: 31.8590\n",
      "Epoch 3/10\n",
      "129/129 [==============================] - 0s 864us/step - loss: 9.3896 - mae: 2.4644 - mse: 9.3896 - val_loss: 27.2567 - val_mae: 5.0265 - val_mse: 27.2567\n",
      "Epoch 4/10\n",
      "129/129 [==============================] - 0s 891us/step - loss: 8.5767 - mae: 2.3712 - mse: 8.5767 - val_loss: 24.1354 - val_mae: 4.6871 - val_mse: 24.1354\n",
      "Epoch 5/10\n",
      "129/129 [==============================] - 0s 898us/step - loss: 8.1365 - mae: 2.3061 - mse: 8.1365 - val_loss: 22.6601 - val_mae: 4.5021 - val_mse: 22.6601\n",
      "Epoch 6/10\n",
      "129/129 [==============================] - 0s 876us/step - loss: 7.9043 - mae: 2.2519 - mse: 7.9043 - val_loss: 22.5348 - val_mae: 4.4890 - val_mse: 22.5348\n",
      "Epoch 7/10\n",
      "129/129 [==============================] - 0s 821us/step - loss: 7.7930 - mae: 2.2291 - mse: 7.7930 - val_loss: 22.1885 - val_mae: 4.4434 - val_mse: 22.1885\n",
      "Epoch 8/10\n",
      "129/129 [==============================] - 0s 812us/step - loss: 7.7400 - mae: 2.2107 - mse: 7.7400 - val_loss: 22.7770 - val_mae: 4.5263 - val_mse: 22.7770\n",
      "Epoch 9/10\n",
      "129/129 [==============================] - 0s 815us/step - loss: 7.7055 - mae: 2.2072 - mse: 7.7055 - val_loss: 22.8134 - val_mae: 4.5309 - val_mse: 22.8134\n",
      "Epoch 10/10\n",
      "129/129 [==============================] - 0s 811us/step - loss: 7.6786 - mae: 2.2004 - mse: 7.6786 - val_loss: 22.6861 - val_mae: 4.5165 - val_mse: 22.6861\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Dense(\n",
    "        units=hp.Int('input_units', min_value=32, max_value=256, step=64),  # Reduced max value and increased step\n",
    "        activation='relu',\n",
    "        input_shape=(X_train_processed.shape[1],)\n",
    "    ))\n",
    "\n",
    "    # Reduced the maximum number of layers\n",
    "    for i in range(hp.Int('n_layers', 1, 3)):\n",
    "        model.add(layers.Dense(\n",
    "            units=hp.Int(f'layer_{i}_units', min_value=32, max_value=256, step=64),  # Simplify layers\n",
    "            activation='relu'\n",
    "        ))\n",
    "\n",
    "    model.add(layers.Dense(1)) \n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-3, 1e-4])),  # Simplified choices\n",
    "        loss='mse',  \n",
    "        metrics=['mae', 'mse'] \n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_mse', \n",
    "    max_trials=10,  \n",
    "    executions_per_trial=2,  \n",
    "    directory='my_dir',\n",
    "    project_name='quick_tune'\n",
    ")\n",
    "\n",
    "tuner.search(\n",
    "    X_train_processed_df, y_train_scaled,\n",
    "    epochs=5,  # Reduced number of epochs for tuning\n",
    "    validation_split=0.1,  # Adjust based on your dataset\n",
    "    batch_size=256  # Increased batch size for faster processing\n",
    ")\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# Build the model with the best hyperparameters and train it on the data\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(\n",
    "    X_train_processed_df, y_train_scaled,\n",
    "    epochs=10,  # You can increase this for the final model training\n",
    "    validation_split=0.1,  # Keep consistent with tuning phase or adjust as necessary\n",
    "    batch_size=256  # Set a fixed batch size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c42eba5-15c8-47a2-9f29-828bdc2202eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check and replace NaN values in the test features \n",
    "if X_test_processed_df.isna().any().any(): \n",
    "    X_test_processed_df = X_test_processed_df.fillna(0)  # Replace NaN with 0 \n",
    "\n",
    "# Check and replace NaN values in the test labels \n",
    "if np.isnan(y_test_scaled).any():  \n",
    "    y_test_scaled = np.nan_to_num(y_test_scaled)  # Replace NaN with 0 (default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2abe9091-b602-468b-96a2-f5ffc0b8154f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 379us/step - loss: 11.8894 - mae: 2.8419 - mse: 11.8894\n",
      "Test Loss: 11.889426231384277, Test MAE: 2.8418984413146973, Test MSE: 11.889426231384277\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_mae, test_mse = model.evaluate(X_test_processed_df, y_test_scaled, batch_size=256)\n",
    "print(f'Test Loss: {test_loss}, Test MAE: {test_mae}, Test MSE: {test_mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "75d1d4b5-f635-4a3e-9345-ee4c602202f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 343us/step\n",
      "R-squared Score: 0.1853582366697647\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_processed_df, batch_size=256)\n",
    "\n",
    "# Calculate R-squared score\n",
    "r_squared = r2_score(y_test_scaled, y_pred)\n",
    "print(f'R-squared Score: {r_squared}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
